"""
Test Case Service Helper Functions

This module contains helper functions specifically for test case generation,
validation, context building, and compliance checking.
"""

from typing import Dict, Any
from langchain.output_parsers import PydanticOutputParser
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.exceptions import OutputParserException
from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception_type

from app.utilities import dc_logger
from app.utilities.constants import Constants
from app.services.llm_services.llm_interface import LLMInterface
from app.services.testcase_service.graph_state import PipelineState
from app.services.reponse_format import AgentFormat
from app.services.prompt_service import PromptService

logger = dc_logger.LoggerAdap(dc_logger.get_logger(__name__), {"dash-test": "V1"})

# Initialize prompt service
prompt_service = PromptService()

# Fetch prompts at module load
brain_agent_prompt = prompt_service.get("brain-orchestrator-agent")
compliance_researcher_prompt = prompt_service.get("compliance-researcher-agent")
context_agent_prompt = prompt_service.get("context-builder-agent")
validation_agent_prompt = prompt_service.get("validator-agent")


class TestCaseHelpers:
    """Helper functions for test case generation workflow"""
    
    @staticmethod
    def generate_testcase(llm: LLMInterface, document: str, compliance_info: str) -> str:
        """
        Generate test cases using LLM.
        
        Args:
            llm: LLM interface instance
            document: Source document content
            compliance_info: Compliance information
        
        Returns:
            str: Generated test cases from LLM
        """
        test_case_prompt_template = prompt_service.get("test-case-generator")
        prompt = test_case_prompt_template.format(document=document, compliance_info=compliance_info)
        llm_output = llm.generate(prompt)
        logger.info("LLM Test Case Generation Completed")
        return llm_output
    
    @staticmethod
    @retry(
        retry=retry_if_exception_type(OutputParserException),
        stop=stop_after_attempt(2),
        wait=wait_fixed(2)
    )
    def validate_testcases(
        llm: LLMInterface,
        document: str,
        llm_output: str,
        output_parser: PydanticOutputParser
    ) -> Dict[str, Any]:
        """
        Validate test cases with LLM and enforce structured format.
        
        Retries parsing if OutputParserException occurs (max 2 attempts, 2 sec delay).
        
        Args:
            llm: LLM interface instance
            document: Source document
            llm_output: Generated test cases
            output_parser: Pydantic parser for validation
        
        Returns:
            Dict: Validated and parsed test cases
        """
        prompt = validation_agent_prompt.format(
            document=document,
            llm_output=llm_output,
            output_format=output_parser.get_format_instructions()
        )
        validated_output = llm.generate(prompt)
        logger.info("LLM Test Case Validation Completed")
        
        try:
            parsed_output = output_parser.parse(validated_output)
        except OutputParserException as e:
            logger.error(f"Parsing failed: {e}. Retrying...")
            raise e
        
        return parsed_output.model_dump()
    
    @staticmethod
    def build_context(llm: LLMInterface, state: PipelineState) -> str:
        """
        Build structured context from document using LLM.
        
        Handles multimodal input if images are present.
        
        Args:
            llm: LLM interface instance
            state: Pipeline state containing document and images
        
        Returns:
            str: Structured context generated by LLM
        """
        system_prompt = SystemMessage(content=context_agent_prompt)
        images = state.get("images", [])
        
        if images and len(images) > 0:
            # Build multimodal content with text + images
            logger.info(f"Building context with {len(images)} images for multimodal analysis")
            
            content_parts = [
                {"type": "text", "text": f'Here is the document: {state["document"]}'}
            ]
            
            for idx, image_uri in enumerate(images):
                content_parts.append({
                    "type": "image_url",
                    "image_url": image_uri
                })
                logger.debug(f"Added image {idx + 1}/{len(images)} to context builder input")
            
            human_message = HumanMessage(content=content_parts)
            response = llm.get_llm().invoke([system_prompt, human_message])
        else:
            # Text-only mode
            logger.info("Building context with text only (no images)")
            response = llm.get_llm().invoke(
                [system_prompt] + [f'Here is the document: {state["document"]}']
            )
        
        logger.info("LLM Context Builder Completed")
        return response.content
    
    @staticmethod
    def plan_compliance(llm: LLMInterface, process_document: str) -> Dict[str, str]:
        """
        Plan compliance steps based on document.
        
        Args:
            llm: LLM interface instance
            process_document: Document to analyze for compliance
        
        Returns:
            Dict: Compliance plan from LLM
        """
        standards = ["FDA", "IEC-62304", "ISO-13485", "ISO-27001"]
        prompt = Constants.fetch_constant("prompts")["compliance_agent1"].format(
            process_document=process_document,
            standards=standards
        )
        llm_output = llm.generate(prompt)
        logger.info("LLM Compliance Planning Completed")
        return {"compliance_plan": llm_output}
    
    @staticmethod
    def enrich_compliance(llm_with_tools: LLMInterface, state: Dict) -> Dict:
        """
        Enrich compliance requirements with authoritative details using RAG and web search.
        
        Args:
            llm_with_tools: LLM interface with tool calling capability
            state: Current workflow state
        
        Returns:
            Dict: Enriched messages with compliance information
        """
        logger.info("Sending LLM Compliance Enrichment Request")
        
        message = {
            "messages": [
                llm_with_tools.invoke(
                    [SystemMessage(content=compliance_researcher_prompt)]
                    + ["Document Information: " + state["document"]]
                    + state["messages"]
                )
            ],
            "llm_calls": state.get('llm_calls', 0) + 1
        }
        
        logger.info("LLM Compliance Enrichment Completed")
        return message
    
    @staticmethod
    def orchestrate_brain_agent(
        llm_tools: LLMInterface,
        state: PipelineState,
        output_parser: PydanticOutputParser
    ) -> AgentFormat:
        """
        Brain agent orchestrator for workflow decision making.
        
        Args:
            llm_tools: LLM interface with tools
            state: Pipeline state
            output_parser: Parser for agent response
        
        Returns:
            AgentFormat: Parsed agent decision
        """
        try:
            system_prompt = SystemMessage(content=brain_agent_prompt)
            message = [system_prompt] + [state["brain_agent_message"]]
            
            if state.get("brain_agent_scratchpad"):
                message.append(f"here is your scratchpad {state['brain_agent_scratchpad']}")
            if state.get("status"):
                message.append(f"\nhere is your previous status {state['status']}")
            if state.get("next_action"):
                message.append(f"\nhere is your previous next action {state['next_action']}")
            if state.get("summary"):
                message.append(f"\nhere is your previous summary {state['summary']}")
            
            response = llm_tools.generate(message)
            logger.info("LLM Brain Agent Completed")
            
            response = output_parser.parse(response)
            return response
        except Exception as e:
            logger.error(f"Error in brain agent: {str(e)}")
            raise e
